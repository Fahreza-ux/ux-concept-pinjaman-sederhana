# Usability Testing Plan

## ðŸŽ¯ Testing Objectives

### Primary Goals
1. **Evaluate Application Flow Efficiency**
   - Measure time to complete loan application
   - Identify friction points in step-by-step process
   - Assess clarity of terminology and instructions

2. **Validate Information Architecture**
   - Test findability of key features (calculator, status tracker, help)
   - Evaluate navigation intuitiveness
   - Assess content hierarchy understanding

3. **Measure User Confidence & Trust**
   - Gauge comfort level with data submission
   - Assess transparency perception
   - Evaluate sense of control throughout process

### Success Criteria
- **Task Completion Rate**: >85% for all critical tasks
- **Time on Task**: <5 minutes for loan application
- **Error Rate**: <10% for form completion
- **Satisfaction Score**: >4.0/5 on System Usability Scale (SUS)

---

## ðŸ‘¥ Participant Recruitment

### Target Participants
**Total**: 8 participants (minimum 5 completes)

**Demographic Criteria**:
- Age: 22-35 years old
- Have used financial apps before
- Considering or have taken loans previously
- Comfortable with mobile technology

**Screening Questions**:
1. "Have you used a loan/financial app in the past 6 months?"
2. "What's your comfort level with mobile apps? (1-5 scale)"
3. "Are you currently considering taking a loan?"

### Recruitment Channels
- Social media communities (Facebook groups, Reddit)
- University student networks
- Professional networking platforms
- Existing user database (if available)

### Incentives
- E-money credit: Rp 50,000 per participant
- Chance to win larger prize: Rp 500,000 (1 winner)

---

## ðŸ§ª Testing Methodology

### Session Structure
**Duration**: 45-60 minutes per session
**Format**: Remote moderated testing via Zoom/Google Meet
**Tools**: Screen sharing, recording, observation notes

### Testing Environment
- **Moderator**: One UX researcher
- **Observers**: Product manager, developer (silent)
- **Platform**: Mobile device (participant's own phone)
- **Prototype**: Interactive Figma prototype

### Data Collection Methods
1. **Task Performance Metrics**
   - Completion time
   - Success/failure rates
   - Error counts and types
   - Click paths and navigation patterns

2. **Qualitative Feedback**
   - Think-aloud protocol
   - Post-task interviews
   - System Usability Scale (SUS)
   - Net Promoter Score (NPS)

---

## ðŸ“‹ Test Scenarios & Tasks

### Scenario 1: Loan Exploration & Calculation
**Background**: 
"You're planning to borrow money for education expenses. You want to explore different loan options before applying."

**Tasks**:
1. "Find the loan calculator feature"
2. "Calculate monthly payments for Rp 8 million over 12 months"
3. "Compare payments for 6-month vs 12-month tenor"
4. "Find information about interest rates and fees"

**Success Metrics**:
- Time to find calculator: <30 seconds
- Accurate calculation understanding
- Clear interest rate comprehension

### Scenario 2: Complete Loan Application
**Background**:
"You've decided to apply for a Rp 10 million loan for laptop purchase. Please complete the application process."

**Tasks**:
1. "Start a new loan application"
2. "Fill in your personal information"
3. "Provide employment and income details"
4. "Review and submit your application"
5. "Check the application status"

**Success Metrics**:
- Completion time: <5 minutes
- Form completion rate: >90%
- Confidence in submission: >4/5 scale

### Scenario 3: Application Status & Support
**Background**:
"You submitted a loan application yesterday and want to check its status and understand next steps."

**Tasks**:
1. "Find your application status"
2. "Understand what the current status means"
3. "Find estimated timeline for decision"
4. "Locate customer support options"
5. "Find answers to common questions"

**Success Metrics**:
- Time to find status: <15 seconds
- Clear understanding of next steps
- Easy access to support channels

---

## ðŸ“Š Data Analysis Plan

### Quantitative Analysis
**Performance Metrics**:
- Task success rates (binary: complete/incomplete)
- Time on task (seconds)
- Error frequency and types
- Click-through rates for key flows

**Statistical Analysis**:
- Descriptive statistics for all metrics
- Correlation analysis between task performance and satisfaction
- Comparative analysis between participant segments

### Qualitative Analysis
**Thematic Analysis**:
1. **Transcribe** all session recordings
2. **Code** transcripts for common themes
3. **Categorize** pain points and positive feedback
4. **Prioritize** issues by frequency and severity

**Affinity Mapping**:
- Group similar observations and feedback
- Identify patterns across participants
- Create "I like, I wish, What if" statements

### Severity Rating Scale
**Critical (P0)**:
- Prevents task completion
- Affects >50% of users
- Requires immediate fix

**High (P1)**:
- Causes significant frustration
- Affects 25-50% of users
- Should be addressed soon

**Medium (P2)**:
- Minor inconvenience
- Affects <25% of users
- Nice to have fixes

**Low (P3)**:
- Cosmetic issues
- No impact on task completion
- Future enhancements

---

## ðŸ“ Testing Script

### Introduction (5 minutes)
"Thank you for participating in our usability study today. We're testing a new loan application interface to understand how we can make it better for users like you.

There are no right or wrong answers - we're testing the design, not you. Please think aloud as you go through the tasks, sharing whatever comes to mind.

The session will take about 45 minutes. We'll start with some background questions, then move to the tasks, and end with some overall feedback. Everything you say will be kept confidential.

Do you have any questions before we begin?"

### Background Questions (5 minutes)
1. "Tell me about your experience with mobile loan applications."
2. "What's been your biggest frustration with financial apps?"
3. "What qualities make you trust a financial service?"

### Task Instructions (30 minutes)
"Now I'll give you some tasks to complete using this prototype. Remember to think aloud as you work through them."

[Administer tasks from Scenarios section]

### Post-Test Questions (5 minutes)
1. "Overall, how would you describe your experience with this app?"
2. "What did you find most confusing or frustrating?"
3. "What did you like most about the experience?"
4. "How confident would you feel using this app for a real loan application?"
5. "Is there anything missing that you'd expect to see?"

### SUS Questionnaire (5 minutes)
[Administer standard System Usability Scale questions]

---

## ðŸ“‹ Consent & Ethics

### Participant Consent
**Verbal Script**:
"I need to get your verbal consent to proceed. Do you consent to:
- Being recorded during this session?
- Having your anonymized feedback used for product improvement?
- Participating in this research study voluntarily?"

**Key Points**:
- Participation is voluntary
- Can withdraw at any time
- Data will be anonymized
- Recording for internal use only

### Data Handling
- **Storage**: Encrypted cloud storage
- **Retention**: 6 months, then deletion
- **Access**: Research team only
- **Anonymization**: Remove personal identifiers

### Incentive Distribution
- E-money credit within 24 hours of completion
- Prize drawing after all sessions complete
- Clear communication about payment timeline

---

## ðŸ—“ï¸ Project Timeline

### Week 1: Preparation
- Finalize test plan and script
- Create interactive prototype
- Recruit participants
- Schedule sessions

### Week 2: Testing Execution
- Conduct 8 usability sessions
- Take detailed notes
- Record sessions (with consent)
- Administer SUS surveys

### Week 3: Analysis & Reporting
- Transcribe and analyze data
- Create findings presentation
- Prioritize recommendations
- Share insights with team

### Week 4: Iteration & Follow-up
- Implement design changes
- Plan follow-up validation testing
- Update design documentation

---

## ðŸ“ˆ Expected Outcomes

### Deliverables
1. **Usability Test Report** with findings and recommendations
2. **Video Clips** of key moments (with consent)
3. **Quantitative Data** dashboard with metrics
4. **Prioritized Action Items** for design improvements

### Success Metrics
- **Identification** of 3-5 critical usability issues
- **Validation** of 80% of design assumptions
- **Clear prioritization** of design improvements
- **Actionable insights** for next design iteration

**Next Step**: Conclusion and project learnings
